<!DOCTYPE html>
<html lang="es">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Document</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/universal-sentence-encoder"></script>
    <link rel="stylesheet" href="style.css" />
  </head>
  <body>
    <main class="container">
      <header>
        <h1>Universal Sentence Encoder</h1>
        <h2 class="subtitle">Interfaz tipo Q&A</h2>
      </header>

      <!-- <ul>
        <li>1- Se usa modelo de tensorflow 'USE'</li>
        <li>2- Se pre-embebe texto como base</li>
        <li>
          3- Se implementa un sistema de preguntas y respuestas basado en la
          similitud sem√°ntica
        </li>
      </ul> -->

      <section class="description-section">
        <h3>Funcionamiento</h3>
        <div class="feature-list">
          <div class="feature-item">
            <h4>üß† Modelo Universal Sentence Encoder (USE)</h4>
            <p>
              Se utiliza el modelo pre-entrenado de TensorFlow que convierte
              texto en vectores de 512 dimensiones, capturando el significado
              sem√°ntico de las oraciones.
            </p>
            <small class="annotation"
              >üìù El modelo se carga desde CDN y funciona completamente en el
              navegador</small
            >
          </div>

          <div class="feature-item">
            <h4>üìö Base de Conocimiento Pre-embebida</h4>
            <p>
              Se procesa una base de datos de texto predefinida, generando
              embeddings (representaciones vectoriales) para cada fragmento de
              informaci√≥n.
            </p>
            <small class="annotation"
              >‚ö° Los embeddings se calculan una sola vez al cargar la
              p√°gina</small
            >
          </div>

          <div class="feature-item">
            <h4>üîç Sistema de Similitud Sem√°ntica</h4>
            <p>
              Cuando haces una pregunta, se calcula su embedding y se compara
              con todos los embeddings de la base usando similitud coseno para
              encontrar las respuestas m√°s relevantes.
            </p>
            <small class="annotation"
              >üéØ El sistema no busca palabras exactas, sino significado
              similar</small
            >
          </div>

          <div class="feature-item">
            <h4>üìä Ranking de Resultados</h4>
            <p>
              Los resultados se ordenan por puntuaci√≥n de similitud (0-1),
              mostrando las respuestas m√°s relevantes primero.
            </p>
            <small class="annotation"
              >üî¢ Solo se muestran resultados con similitud > 0.5</small
            >
          </div>
        </div>
      </section>

      <form id="controls" action="javascript:void(0);">
        <label for="question-input" class="sr-only"
          >Escribi tus preguntas ac√°</label
        >
        <input
          type="text"
          id="question-input"
          placeholder="Escribi tus preguntas ac√°..."
        />
        <button type="button" id="search-button" class="button">
          Preguntar
        </button>
      </form>

      <section id="result-box" aria-labelledby="results-heading">
        <h2 id="results-heading" class="sr-only">Resultados</h2>
        <p id="initial-msg"></p>
      </section>

      <section aria-labelledby="console-heading">
        <h2 id="console-heading">Consola</h2>
        <div id="log-console"></div>
      </section>
    </main>

    <script>
      const dataset = [];

      const App = {
        model: null,
        embeddings: null,
        threshold: 0.6, // umbral de similitud para mostrar resultados
        typingSpeed: 55, // en ms, vamos a simular un typing como streaming de texto

        // Inicializa la app: carga modelo y embebe dataset
        async init() {
          // Carga el modelo Universal Sentence Encoder (USE) desde CDN.
          // Este modelo convierte texto en vectores num√©ricos que capturan el significado,
          // para que podamos comparar "ideas" m√°s que palabras exactas.
          log("üöÄ Cargando modelo...");
          this.model = await use.load();
          log("‚úÖ Modelo cargado.");

          // Genera los embeddings (vectores de significado) para cada pregunta del dataset.
          // Luego los normaliza para que todas las "flechas" tengan el mismo tama√±o,
          // porque lo que importa es la direcci√≥n (el significado), no la longitud.
          log("üß† Embedding del dataset...");
          const questions = dataset.map((q) => q.question);
          const rawEmbeddings = await this.model.embed(questions);
          this.embeddings = rawEmbeddings;
          log(`‚úÖ Dataset cargado con ${dataset.length} items.`);
          // Habilita el bot√≥n de b√∫squeda s√≥lo cuando todo est√° listo.
          ui.searchButton.disabled = false;
        },

        async cosineSimilarity(vecA, vecB) {
          // Se normalizan los vectores para que solo importe su direcci√≥n (su significado).
          // Luego se multiplica elemento a elemento y se suma todo: esto da el "coseno de similitud".
          // Cuanto m√°s cercano a 1, m√°s parecidos son.

          // tf.tidy() elimina autom√°ticamente los tensores temporales dentro del bloque.
          // Evita que se acumulen en memoria y cause fugas (memory leaks).
          const scoreTensor = tf.tidy(() => {
            // squeeze() Elimina dimensiones extra innecesarias (por ejemplo, [1,512] pasa a [512])
            const a = vecA.squeeze();
            const b = vecB.squeeze();
            const aNorm = a.div(tf.norm(a));
            const bNorm = b.div(tf.norm(b));
            return aNorm.mul(bNorm).sum(); // retorna un tf.Scalar
          });

          const score = (await scoreTensor.data())[0];
          return score;
        },

        async handleQuery(query) {
          const cleanQuery = query.toLowerCase().trim();
          const qEmbedding = await this.model.embed([cleanQuery]);
          const results = [];

          for (let i = 0; i < dataset.length; i++) {
            const itemEmb = this.embeddings.slice([i, 0], [1, -1]);
            // Selecciona la fila i completa del tensor 2D de embeddings
            // -1 significa ‚Äútodas las columnas‚Äù
            const score = await this.cosineSimilarity(qEmbedding, itemEmb);
            results.push({ ...dataset[i], score });
          }

          qEmbedding.dispose();
          return results.sort((a, b) => b.score - a.score);
        },

        async runSearch() {
          const query = ui.questionInput.value.trim();
          if (!query) return;

          ui.resultBox.innerHTML = "";
          log(`üìù Pregunta: "${query}"`);

          const results = await this.handleQuery(query);
          const top3 = results.slice(0, 3);
          console.log(
            "Top 3 scores:",
            top3.map((r) => ({ score: r.score, question: r.question }))
          );

          if (top3[0].score < 0.2) {
            typeWriter(
              ui.resultBox,
              `‚ö†Ô∏è No se encontraron coincidencias relevantes.\nüìä Mejor score: ${top3[0].score.toFixed(
                3
              )}\n\nüí° Intenta reformular tu pregunta o usar palabras clave diferentes.`
            );
          } else {
            // Filtrar solo los que superen el threshold para mostrar
            const goodResults = top3.filter((r) => r.score > this.threshold);

            if (goodResults.length === 0) {
              // Mostrar el mejor resultado aunque no supere el threshold
              typeWriter(
                ui.resultBox,
                `ü§î Resultado con baja confianza:\n\n${
                  top3[0].answer
                }\nüìä Score: ${top3[0].score.toFixed(
                  3
                )}\n\nüí° ¬øEra esto lo que buscabas?`
              );
            } else {
              typeWriter(
                ui.resultBox,
                goodResults
                  .map(
                    (r, i) =>
                      `${i + 1}. ${r.answer}\nüìä Score: ${r.score.toFixed(3)}`
                  )
                  .join("\n\n")
              );
            }
          }
          //   const filteredResults = results.filter(
          //     (r) => r.score > this.threshold
          //   );

          //   if (filteredResults.length === 0) {
          //     typeWriter(
          //       ui.resultBox,
          //       `‚ö†Ô∏è No se encontraron coincidencias relevantes.\nüìä Mejor score: ${results[0].score.toFixed(
          //         3
          //       )}`
          //     );
          //   } else {
          //     const top3 = filteredResults.slice(0, 3);
          //     typeWriter(
          //       ui.resultBox,
          //       top3
          //         .map(
          //           (r, i) =>
          //             `${i + 1}. ${r.answer}\nüìä Score: ${r.score.toFixed(3)}`
          //         )
          //         .join("\n\n")
          //     );
          //   }
        },
      };

      const ui = {
        questionInput: document.getElementById("question-input"),
        searchButton: document.getElementById("search-button"),
        resultBox: document.getElementById("initial-msg"),
        logConsole: document.getElementById("log-console"),
      };

      //funciones auxiliares
      function typeWriter(
        element,
        text,
        speed = App.typingSpeed,
        onComplete = null
      ) {
        let i = 0;
        element.innerHTML = "";
        function type() {
          if (i < text.length) {
            element.innerHTML +=
              text.charAt(i) === "\n" ? "<br>" : text.charAt(i);
            i++;
            setTimeout(type, speed);
          } else if (onComplete) {
            onComplete();
          }
        }
        type();
      }

      function log(msg) {
        const logLine = document.createElement("div");
        const time = new Date().toLocaleTimeString();
        logLine.innerHTML = `<span style="color: #888;">[${time}]</span> ${msg}`;
        ui.logConsole.appendChild(logLine);
        ui.logConsole.scrollTop = ui.logConsole.scrollHeight;
        if (ui.logConsole.children.length > 100) {
          ui.logConsole.removeChild(ui.logConsole.firstChild);
        }
      }

      document.addEventListener("DOMContentLoaded", () => {
        App.init();
        ui.searchButton.addEventListener("click", () => App.runSearch());
      });
    </script>
  </body>
</html>
